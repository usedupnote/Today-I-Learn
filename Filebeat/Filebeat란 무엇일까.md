## `Filebeat란 무엇일까?`

![image](https://user-images.githubusercontent.com/45676906/205083158-ca548887-2920-4c9a-b60b-4d9157f4264b.png)

서버나 시스템을 운영하다 보면 수 많은 로그들이 파일 형태로 발생한다. 파일비트는 이런 로그 파일을 쉽게 수집하도록 도와주면 궁긍적으로 엘라스틱과 키바나를 이용해 로그를 추적하고 통계를 만들어 활용할 수 있게 도와준다.

<br>

[파일비트 구성요소]

- `입력`: 설정 파일에서 하베스터에 대한 입력 소스를 정한다. 파일 비트는 하나 혹은 여러 개의 입력을 가질 수 있다.
- `하베스터`: 입력에 명시된 파일을 직접 수집하는 주체다. 파일은 하나의 하베스터를 가지며, 하베스터는 파일을 한 줄씩 읽고 내보내는 역할을 한다. 또한 파일을 열고 닫는 역할도 한다. 하베스터가 실행되는 동안에는 파일 디스크립터가 열려 있다.
- `스풀러`: 하베스터가 수집한 이벤트를 엘라스틱서치나 로그스태시 같은 장소로 전달한다.

```yaml
filebeat.inputs:
- type: log
  enabled: true
  paths: 
    - elasticsearch/logs/*.log

output.elasticsearch:
  hosts: ["localhost:9200"]
  index: "index.%{+yyyy.MM.dd}"  
  # Optional
  protocol: "http"
  username: "username"   
  password: "password"

setup.kibana:
  host: "localhost:5601"
```

1. `filebeat.inputs.paths`에 지정된 파일들이 `Filebeat`를 통해 `ElasticSearch`에 적재된다.
2. ElasticSearch에 적재될 때 인덱스 테이블 이름은 `index.%{+yyyy.MM.dd}`으로 생성된다.(ex: index.2022.12.21 즉, 날짜별로 인덱스가 생기는 것임)

<br>

[파일비트 구성요소]

- `log`: 가장 기본이 되는 타입으로, 파일시스템의 지정한 경로에서 로그 파일을 읽어 들인다.
- `container`: 도커 같은 컨테이너의 로그를 수집하기 위한 입력으로, 파일을 읽어 들인다는 점에서 log와 유사하다.
- `s3`: log 타입과 유사한, 아마존 웹 서비스의 S3 버킷에 위치한 파일을 읽어 들인다.
- `kafka`: 다른 타입과는 다르게 파일을 읽어 들이는 대신 카프카의 토픽을 읽어 들인다. 

<br>

[파일비트 아웃풋 타입]

- `elasticsearch`: 가장 많이 사용되는 타입으로, 수집한 이벤트를 엘라스틱서치로 직접 인덱싱한다.
- `logstash`: 다수의 비츠를 사용해 엘라스틱서치로 전송되는 인덱싱 레퀘스트의 양이 많거나, 비츠나 인제스트 노드 수준에서 처리하기 어려운 가공 작업이 필요할 때 별도의 로그스태시를 구축한 후 수집한 이벤트를 전송한다. 다수의 인덱싱 요청이 로그스태시에서 단일 벌크 리퀘스트로 묶여 인덱싱 효율의 개선을 기대할 수 있다.
- `kafka`: 파일비트에서 1차적으로 수집한 이벤트를 카프카로 전송한다. 카프카는 좀 더 안정적인 수집 파이프라인을 구성할 때 신뢰할 만한 중간 저장소/큐이므로 수집 중 장애 발생 시 데이터 손실을 최소화하기 위한 방안으로 활용된다.
- `console`: 수집한 이벤트를 시스템 콘솔에 출력한다. 일반적으로 수집이 정상적으로 이뤄지는지 입력 설정을 테스트하기 위한 목적으로 사용된다.